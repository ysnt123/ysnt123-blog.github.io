<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hadoop Stream 排序reduce</title>
    <url>/2023/05/23/hadoopSteamSort/</url>
    <content><![CDATA[<h1 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h1><pre><code>已知一天有N个用户，每个用户每天有多条数据，且出现在不同的timestamp。如何处理，使得数据按照用户粒度进行聚合
</code></pre>
<span id="more"></span>
<h1 id="如何解决"><a href="#如何解决" class="headerlink" title="如何解决"></a>如何解决</h1><pre><code>只要在计算的时候加入四行参数即可：
</code></pre>
<pre><code class="hadoop">    -jobconf stream.num.map.output.key.fields=4 \
    -jobconf stream.map.output.field.separator=&quot;\t&quot; \
    -jobconf mapred.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator \
    -jobconf mapred.text.key.comparator.options=&quot;-k2,2 -k1,1nr -k4,4 -k3,3nr&quot; \
</code></pre>
<pre><code>一个完整的demo设置如下：
</code></pre>
<pre><code class="hadoop">$&#123;HADOOP_BIN&#125; streaming  -conf $&#123;XML_CONF&#125; \
    -cacheArchive &quot;$&#123;AFS_PYTHON&#125;&quot; \
    -input $HADOOP_INPUT \
    -output $HADOOP_OUTPUT \
    -mapper &quot;./python3.8/bin/python mapper.py&quot; \
    -reducer &quot;./python3.8/bin/python reducer.py&quot; \
    -file mapper.py \
    -file reducer.py \
    -jobconf stream.num.map.output.key.fields=4 \
    -jobconf stream.map.output.field.separator=&quot;\t&quot; \
    -jobconf mapred.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator \
    -jobconf mapred.text.key.comparator.options=&quot;-k2,2 -k1,1nr -k4,4 -k3,3nr&quot; \
    -jobconf mapred.job.name=$TASK_NAME \
    -jobconf mapred.job.map.capacity=250 \
    -jobconf mapred.map.tasks=250 \
    -jobconf mapred.reduce.tasks=1 \
    -jobconf stream.non.zero.exit.is.failure=false \
    -jobconf stream.memory.limit=30000 \
    -jobconf mapred.map.over.capacity.allowed=false \
    -jobconf mapred.job.priority=VERY_HIGH \
    -jobconf abaci.job.base.environment=centos6u3_hadoop
</code></pre>
<pre><code>map阶段直接print，在reduce之前会有一个排序好的结果，一个比较垃圾的reducer.py的demo：
</code></pre>
<pre><code class="python"># -*- coding: utf-8 -*-
import io
import sys
sys.stdin = io.TextIOWrapper(sys.stdin.buffer, encoding=&#39;utf-8&#39;)
sys.stdout = io.TextIOWrapper(sys.stdout.buffer,encoding=&#39;utf-8&#39;)
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding=&#39;utf-8&#39;)
cur_oaid = &quot;&quot;
cur_st = &quot;&quot;
for line in sys.stdin:
    line = line.strip()
    words = line.split(&quot;\t&quot;)
    try:
        event_day,oaid,st,ql,tl,clk = words[0],words[1],words[2],eval(words[3]),eval(words[4]),int(words[5])
        #print(ql)
        #print(st,oaid)
    except:
        continue
    if oaid == &quot;-&quot;:
        continue
    # 是否首个,初始化
    if cur_oaid == &quot;&quot;:
        cur_oaid = oaid
        # cur_st = st
        cur_q_dict = &#123;&#125;
        cur_t_dict = &#123;&#125;
    # 是否和上一条一样：
    if cur_oaid == oaid:
        #print(&quot;yes&quot;)
        # title直算
        if clk:
            for s in tl:
                if s not in cur_t_dict:
                    cur_t_dict[s]=clk
                else:
                    cur_t_dict[s]+=clk
        
        # query :取distinct timestamp
        # 如果是第一条
        if cur_st==&quot;&quot;:
            qs = 1
            cur_st = st
        # 如果不是第一条，且不一样
        elif st != cur_st:
            qs = 1
            cur_st = st
        else:
            qs = 0
        #print(qs)
        for ss in ql:
            if ss not in cur_q_dict:
                cur_q_dict[ss]=qs
            else:
                cur_q_dict[ss]+=qs
    else:
        # 打印 cur_oaid，cur_q_dict（sort），cur_t_dict（sort）
        # 如果和上一条不一样，先把上一条打印一下
        cur_q_dict_list = list(sorted(cur_q_dict.items(),key=lambda x:x[1],reverse=True))
        cur_q_dict_list = [[list(i)[0],str(list(i)[1])] for i in cur_q_dict_list]
        cur_q_dict_list = [&quot;\002&quot;.join(i) for i in cur_q_dict_list]
        cur_q_dict_list = &quot;\001&quot;.join(cur_q_dict_list)
        cur_t_dict_list = list(sorted(cur_t_dict.items(),key=lambda x:x[1],reverse=True))
        cur_t_dict_list = [[list(i)[0],str(list(i)[1])] for i in cur_t_dict_list]
        cur_t_dict_list = [&quot;\002&quot;.join(i) for i in cur_t_dict_list]
        cur_t_dict_list = &quot;\001&quot;.join(cur_t_dict_list)        
        print(cur_oaid+&quot;\t&quot;+str(cur_q_dict_list)+&quot;\t&quot;+str(cur_t_dict_list))

        # 刷新cur信息
        cur_oaid = oaid
        # cur_st = st
        cur_q_dict = &#123;&#125;
        cur_t_dict = &#123;&#125;        
        # title直算
        if clk:
            for s in tl:
                if s not in cur_t_dict:
                    cur_t_dict[s]=clk
                else:
                    cur_t_dict[s]+=clk
        cur_st = st
        qs=1
        for ss in ql:
            if ss not in cur_q_dict:
                cur_q_dict[ss]=qs
            else:
                cur_q_dict[ss]+=qs

# 读完之后
cur_q_dict_list = list(sorted(cur_q_dict.items(),key=lambda x:x[1],reverse=True))
cur_q_dict_list = [[list(i)[0],str(list(i)[1])] for i in cur_q_dict_list]
cur_q_dict_list = [&quot;\002&quot;.join(i) for i in cur_q_dict_list]
cur_q_dict_list = &quot;\001&quot;.join(cur_q_dict_list)
cur_t_dict_list = list(sorted(cur_t_dict.items(),key=lambda x:x[1],reverse=True))
cur_t_dict_list = [[list(i)[0],str(list(i)[1])] for i in cur_t_dict_list]
cur_t_dict_list = [&quot;\002&quot;.join(i) for i in cur_t_dict_list]
cur_t_dict_list = &quot;\001&quot;.join(cur_t_dict_list)         
print(cur_oaid+&quot;\t&quot;+str(cur_q_dict_list)+&quot;\t&quot;+str(cur_t_dict_list))
</code></pre>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop Stream 中文乱码解决</title>
    <url>/2023/05/22/hadoop-use-bug/</url>
    <content><![CDATA[<h1 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h1><pre><code>在使用hadoop的时候，如果输入有中文，那么经常会遇到一个问题————乱码！
这里记录一下mapper.py和reducer.py里设置方法。
</code></pre>
<span id="more"></span>
<h1 id="问题出现的原因"><a href="#问题出现的原因" class="headerlink" title="问题出现的原因"></a>问题出现的原因</h1><pre><code>hadoop提交作业，把文件打包到集群上，用集群机器去进行map reduce～
会出现这种问题，很大原因就是集群机器默认的读入和打印的格式和我们数据的输入、想要的输出格式不一样
</code></pre>
<h1 id="怎么解决？"><a href="#怎么解决？" class="headerlink" title="怎么解决？"></a>怎么解决？</h1><ul>
<li>python2<br>  如果是python2，可以使用reload</li>
</ul>
<pre><code class="python">sys.setdefaultencoding(&#39;utf8&#39;)
</code></pre>
<ul>
<li>python3<br>  如果是python3，没有sys.setdefaultencoding，则使用：</li>
</ul>
<pre><code class="python">sys.stdin = io.TextIOWrapper(sys.stdin.buffer, encoding=&#39;utf-8&#39;)
sys.stdout = io.TextIOWrapper(sys.stdout.buffer,encoding=&#39;utf-8&#39;)
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding=&#39;utf-8&#39;)
</code></pre>
<p>完美解决～</p>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>debug</tag>
      </tags>
  </entry>
  <entry>
    <title>Proof of Love</title>
    <url>/2023/05/18/Proog_Of_Love/</url>
    <content><![CDATA[<p>自2020.10.14起，修修爱贞贞，贞贞爱修修。<br>期限：+∞</p>
]]></content>
      <categories>
        <category>个人证书</category>
      </categories>
      <tags>
        <tag>纯属秀恩爱</tag>
      </tags>
  </entry>
</search>
